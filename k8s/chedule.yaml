## https://youtu.be/rDCWxkvPlAw

# 1. Scheduling Pod on a Specific Node

# Problem
# The primarily responsibility of kube-scheduler is to find a node where to place a pod. But how can we control this process?
# We’d like to run a pod on specific node by its name.

# Using nodeName Property
# It’s the simplest form of node selection constraint, but due to its limitations it is typically not used.

# Documentation:
# https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodename
# https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/

# Example:

apiVersion: v1
kind: Pod
metadata:
  name: busybox
spec:
  nodeName: << node hostname >>
  containers:
  - name: main
    image: busybox:1.34
    command:
    - sleep
    - infinity
    
# Task:
# Please, update exercise deployment so that it runs pods on node01 host using nodeName only

# Verify:
# $ kubectl get pods -o wide
# NAME                        READY   STATUS    RESTARTS   AGE   IP          NODE     NOMINATED NODE   READINESS GATES
# exercise-6b4cb7c4cb-bp2hf   1/1     Running   0          61s   10.42.0.3   node01   <none>           <none>

####################################################################################################################################

# 2. Scheduling Pod on a Node by its Label
# Problem
# We’d like to run pods on any host from “a pool of suitable hosts”.

# Using nodeSelector Property
# The nodeSelector is the simplest recommended form of node selection constraint. nodeSelector is a field of PodSpec. It specifies a map of key-value pairs. For the pod to be eligible to run on a node, the node must have each of the indicated key-value pairs as labels (it can have additional labels as well). The most common usage is one key-value pair.

# Built-in node labels
# In addition to the labels you attach, nodes come pre-populated with a standard set of labels. These labels are:
#   kubernetes.io/hostname
#   failure-domain.beta.kubernetes.io/zone
#   failure-domain.beta.kubernetes.io/region
#   topology.kubernetes.io/zone
#   topology.kubernetes.io/region
#   beta.kubernetes.io/instance-type
#   node.kubernetes.io/instance-type
#   kubernetes.io/os
#   kubernetes.io/arch

# Documentation:
# https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector

# Example
apiVersion: v1
kind: Pod
metadata:
  name: busybox
spec:
  nodeSelector:
    kubernetes.io/os: linux
  containers:
  - name: busybox
    image: busybox:1.34
    command:
    - sleep
    - "300"
    
# In that case, Pod will be assigned to the node with kubernetes.io/os=linux label. 
# There’s a list of predefined labels, but you can also use your custom labels on hosts.

# Task:
# We’ve already created exercise deployment for you.

# Let’s split nodes of our cluster to zones:

# master node: topology.kubernetes.io/zone=eu-east-1a label
# node01 node: topology.kubernetes.io/zone=eu-east-1b label
# node02 node: topology.kubernetes.io/zone=eu-east-1c label

# Update exercise deployment:
# All replicas should run on the node(s) with topology.kubernetes.io/zone=eu-east-1c label

apiVersion: apps/v1
kind: Deployment
metadata:
  name: exercise-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: exercise-app
  template:
    metadata:
      labels:
        app: exercise-app
    spec:
      nodeSelector:
        topology.kubernetes.io/zone: eu-east-1c
      containers:
      - name: exercise-container
        image: exercise-image
        
# Solution:

        
# # For example, to label the master node with topology.kubernetes.io/zone=eu-east-1a:
# $ kubectl label nodes master topology.kubernetes.io/zone=eu-east-1a
# # For node01 node with topology.kubernetes.io/zone=eu-east-1b:
# $ kubectl label nodes node01 topology.kubernetes.io/zone=eu-east-1b
# # For node02 node with topology.kubernetes.io/zone=eu-east-1c:
# $ kubectl label nodes node02 topology.kubernetes.io/zone=eu-east-1c

# Once the nodes are labeled, you can then update your deployment to schedule pods on specific nodes based on the topology.kubernetes.io/zone label by using nodeSelector.
# $ kubectl patch deployment exercise -p '{"spec": {"template": {"spec": {"nodeSelector": {"topology.kubernetes.io/zone": "eu-east-1c"}}}}}'

# Verify:
# Checking Node Topology Lables:

# $ kubectl get nodes --label-columns=topology.kubernetes.io/region,topology.kubernetes.io/zone
# NAME     STATUS   ROLES                         AGE   VERSION        REGION      ZONE
# node01   Ready    worker                        15m   v1.21.5+k3s2   eu-east-1   eu-east-1b
# node02   Ready    worker                        15m   v1.21.5+k3s2   eu-east-1   eu-east-1c
# master   Ready    control-plane,master,worker   15m   v1.21.5+k3s2   eu-east-1   eu-east-1a

# Checking all pods scheduled to the proper zone:

# $ kubectl describe pod exercise-... | grep 'Node'
# Node:         node02/172.31.0.4
# Node-Selectors:  topology.kubernetes.io/zone=eu-east-1c
# ...

# $ kubectl get pods -o wide
# NAME                        READY   STATUS    RESTARTS   AGE   IP          NODE     NOMINATED NODE   READINESS GATES
# exercise-6b89dc68f9-qxg9j   1/1     Running   0          18s   10.42.1.6   node02   <none>           <none>
# exercise-6b89dc68f9-dldbj   1/1     Running   0          19s   10.42.1.5   node02   <none>           <none>
# exercise-6b89dc68f9-hm7tm   1/1     Running   0          18s   10.42.1.7   node02   <none>           <none>

