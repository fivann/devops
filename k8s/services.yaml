# Service - an abstract way to expose an application running on a set of Pods as a network service (thought it’s an internal LoadBalancer).
# https://youtu.be/5lzUpDtmWgM

#   kubectl get svc
#   kubectl get svc -o wide
#   kubectl get svc --all-namespaces
#   kubectl describe svc -n <<namespace name>> <<service name>>
#   kubectl get svc -n <<namespace name>> <<service name>> -o yaml

# Endpoint - a list of backends (pods ip addresses):
#   kubectl get ep
#   kubectl describe ep -n <<namespace name>> <<service name>>

# Service Key Points:
# Similar to LoadBalancers, service aggregates pods
# If any new pods had a specific label, the service would know how to send traffic to it.
# Service selector matches a pod label
# Service (usually) has Cluster internal IP (of the same network where Pods are running) and is always avaialable by its name

# Along with its IP, service has other key options:
# port - TCP Port for incoming connections
# targetPort - TCP port of destination (backend) pod

# Endpoint
# endpoint (also ep) is an automatically configured list of backends matched by service selector
# endpoint can have items from outside the cluster (external IPs or domain names)
# Endpoint (ep) is a list of backends

# Documentation
# https://kubernetes.io/docs/concepts/services-networking/service/
# https://theithollow.com/2019/02/04/kubernetes-endpoints/

# Q2 How many Services exist in the cluster (all nsamespaces)?
# kubectl get services --all-namespaces

# Q4 What is the targetPort configured on the kubernetes service?
# kubectl describe service kubernetes 


# 2. Service Type: ClusterIP
# So, in Kubernetes Service is a set of pods that works together and are defined by a label selector, services decouple work definitions from the pods.

# ClusterIP exposes the Service on a cluster-internal IP. Choosing this value makes the Service only reachable from within the cluster. This is the default ServiceType.


# Cluster IP
# Defines a logical set of pods and policy by which to access them

# it is an abstraction on top of the pods
# it uses selector to create a logical set of pods
# it gets stable Virtual IP and Port
# it is only available within K8s Cluster

# ClusterIP Explained:
# https://youtu.be/dVDElh_Kd48
# Service Example:
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: MyApp
  ports:
    - protocol: TCP
      port: 80
      targetPort: 9376

# Here, service my-service has own ip address (ClusterIP, will be provided automatically) in Kuberenetes internal pod network, ready to get requests on port=80 and will downstream them to pods labeled app=MyApp to port 9376


# Task:

# Create pod-info-svc service for pod-info-app deployment

# Name: pod-info-svc
# Type: ClusterIP
# Service Port: 80
# Service TargetPort: 80
#  Investigate pod-info-app deployment and choose selector
#  Do not change pod-info-app deployment

kubectl create -f - <<EOF
apiVersion: v1
kind: Service
metadata:
  name: pod-info-svc
  labels:
    app: pod-info-app
spec:
  type: ClusterIP
  ports:
  - port: 80
    targetPort: 80
  selector:
    app: pod-info-app
EOF



# Run a pod (based on image busybox:1.28) and execute following commands (as given below) inside this pod and save outputs into files on client host:
# wget -q -O- pod-info-svc save to /root/testing-clusterip-web.log (on client node!)
# nslookup pod-info-svc save to /root/testing-clusterip-nslookup.log (on client node!)

# ( echo wget -q -O- pod-info-svc | kubectl run test --image busybox:1.27 -i --rm -- sh ) > /root/testing-clusterip-web.log 
# ( echo nslookup pod-info-svc | kubectl run test --image busybox:1.27 -i --rm -- sh ) > /root/testing-clusterip-nslookup.log
# Example:
# # kubectl run test --image busybox:1.28 -i --tty --rm -- sh
# If you don't see a command prompt, try pressing enter.

# / # nslookup pod-info-svc
# Server:    10.96.0.10
# Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local

# Name:      pod-info-svc
# Address 1: 10.101.149.153 pod-info-svc.default.svc.cluster.local

# / # wget -q -O- pod-info-svc
# ...
# System Info:
#   - Hostname: "pod-info-app-868c998896-lnwrr"
#   - Address: "10.244.1.12"
#   - System Time: "Sunday, 22-Nov-20 08:53:21 UTC"
#   - System Up Time: "29.39s"
#   - Run as User: "root(0:0)"
# ...

# /# wget -q -O- pod-info-svc.default.svc.cluster.local
# ...
# System Info:
#   - Hostname: "pod-info-app-868c998896-lnwrr"
#   - Address: "10.244.1.12"
#   - System Time: "Sunday, 22-Nov-20 08:57:51 UTC"
#   - System Up Time: "5m0.02s"
#   - Run as User: "root(0:0)"
# ...

# / # exit
# Session ended, resume using 'kubectl attach test -c test -i -t' command when the pod is running
# pod "test" deleted
# Problems?
# nslookup doesn’t work properly on busybox:1.34?
# Yes, it’s well-known bug. Use busybox:1.27 or busybox:1.28 (< 1.28.4)

# $ kubectl run test --image busybox:1.34 -i --rm -- nslookup pod-info-svc
# If you don't see a command prompt, try pressing enter.
# Server:         10.43.0.10
# Address:        10.43.0.10:53

# Name:   pod-info-svc.default.svc.cluster.local
# Address: 10.43.188.3

# *** Can't find pod-info-svc.svc.cluster.local: No answer
# *** Can't find pod-info-svc.cluster.local: No answer
# *** Can't find pod-info-svc.default.svc.cluster.local: No answer
# *** Can't find pod-info-svc.svc.cluster.local: No answer
# *** Can't find pod-info-svc.cluster.local: No answer

# pod "test" deleted
# kubectl run ... stuck and didn’t show output?
# Thought this should work, but it doesn’t:

# $ kubectl run test --image busybox:1.28 -i --rm -- nslookup pod-info-svc
# ## long delay
# pod "test" deleted
# error: timed out waiting for the condition
# Unfortunately yes, it should work, but it doesn’t do it for busybox:1.34 images. Why? No idea.
# But what to do?
# Let’s try this:

# $ echo nslookup pod-info-svc | kubectl run test --image busybox:1.27 -i --rm -- sh
# Service Domain Name
# Given you have service my-app-service created in my-app-ns namespace, you can reach it (internally, within cluster) by following names:

# Domain Name Visibility
# my-app-service  within my-app-ns
# my-app-service.my-app-ns  within my-app-ns, from other namespace
# my-app-service.my-app-ns.svc  within my-app-ns, from other namespace
# my-app-service.my-app-ns.svc.cluster.local  within my-app-ns, from other namespace
# Documentation:
# https://kubernetes.io/docs/concepts/services-networking/service/
# https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types
# https://dzone.com/articles/routing-external-traffic-into-your-kubernetes-serv


# Task:
# An application called simple-web-app is running in the cluster.
# Create ClusterIP Service and set externalIPs to master node (set its IP address):
# Name: my-web-service
# Service Type: ClusterIP
# Service Port: 80
# Target Port: 80
# externalIPs: find master node IP
#  Please choose proper pod selector

# # kubectl describe node master | grep IP
#   InternalIP:  172.31.0.2

apiVersion: v1
kind: Service
metadata:
  name: my-web-service
spec:
  type: ClusterIP
  selector:
    app: simple-web-app  # choose the proper pod selector
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  externalIPs:
  - 172.31.0.2
  
## =======================================================
# Service Type: LoadBalancer
# If your Kubernetes cluster has integration with Cloud (using cloud-controller-manager), 
# creating service type LoadBalancer creates Cloud Load Balancer and automatically integrates it with your K8s’ service.
# For On-prem Kubernetes Clusters you can use “MetalLB” solution.

# Brief Explanation:
# https://youtu.be/xCsz9IOt-fs

# Example:
# On cloud providers which support external load balancers, 
# setting the type field to LoadBalancer provisions a load balancer for your Service. 
# The actual creation of the load balancer happens asynchronously, 
# and information about the provisioned balancer is published in the Service’s 
# .status.loadBalancer field. For example:

apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: MyApp
  ports:
    - protocol: TCP
      port: 80
      targetPort: 9376
  clusterIP: 10.0.171.239
  type: LoadBalancer
status:
  loadBalancer:
    ingress:
    - ip: 192.0.2.127
    
# Here, clusterIP: 10.0.171.239 and ip: 192.0.2.127 will be created automatically

# Task:
# We need to expose our application externally. DNS name will be assigned to this LB IP separately.
# Please, follow the next action items:

# Namespace: prod
# Service Name: book-shelf-service
# Product Name (deployment): book-shelf
# Create a service with type LoadBalancer (IP address will be assinged automatically from platform managed pool)
# Application Port - find it by checking pod logs

apiVersion: v1
kind: Service
metadata:
  name: book-shelf-service
  namespace: prod
spec:
  type: LoadBalancer
  selector:
    app: book-shelf
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80


# Verification:
# $ kubectl get svc -n prod
# NAME         TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE
# book-shelf   LoadBalancer   10.97.92.142   50.60.70.35   80:32419/TCP   8s

# $ curl 50.60.70.35
# Title: Winged Vortex
# Author: James Martin

# $ curl 50.60.70.35
# Title: Day of Pluto
# Author: Benjamin Anderson

# $ curl 50.60.70.35
# Title: Sirius Grieving
# Author: Benjamin Harris

# Documentation:
# https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer


# Service Topology
# Only Node Local Endpoints
# A Service that only routes to node local endpoints. If no endpoints exist on the node, traffic is dropped:
# Example:

apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: my-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 9376
  topologyKeys:
    - "kubernetes.io/hostname"
    
# Documentation:
# https://kubernetes.io/docs/concepts/services-networking/service-topology/#only-node-local-endpoints

# Prefer Node Local Endpoints
# A Service that prefers node local Endpoints but falls back to cluster wide endpoints if node local endpoints do not exist:
# Example:

apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: my-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 9376
  topologyKeys:
    - "kubernetes.io/hostname"
    - "*"
# Documentattion:
# https://kubernetes.io/docs/concepts/services-networking/service-topology/#prefer-node-local-endpoints

# Only Zonal or Regional Endpoints
# A Service that prefers zonal then regional endpoints. If no endpoints exist in either, traffic is dropped.
# Example:

apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: my-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 9376
  topologyKeys:
    - "topology.kubernetes.io/zone"
    - "topology.kubernetes.io/region"
    
# Documentation:
# https://kubernetes.io/docs/concepts/services-networking/service-topology/#only-zonal-or-regional-endpoints

# Prefer Node Local, Zonal, then Regional Endpoints
# A Service that prefers node local, zonal, then regional endpoints but falls back to cluster wide endpoints.
# Example:

apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: my-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 9376
  topologyKeys:
    - "kubernetes.io/hostname"
    - "topology.kubernetes.io/zone"
    - "topology.kubernetes.io/region"
    - "*"
# Documentattion:
# https://kubernetes.io/docs/concepts/services-networking/service-topology/#prefer-node-local-zonal-then-regional-endpoints
